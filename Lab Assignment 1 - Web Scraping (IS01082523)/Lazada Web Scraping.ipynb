{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e83b41-3319-43e3-b2f4-0f39e74d9eee",
   "metadata": {},
   "source": [
    "Reshma a/p Ganesan (IS01082523) and Yasmine Essam (IS01082525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e32dfae-43b9-4c2b-9919-ced29453f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1...\n",
      "Page 1 scraped. Total reviews so far: 5\n",
      "Clicking page 2 button...\n",
      "Scraping Page 2...\n",
      "Page 2 scraped. Total reviews so far: 10\n",
      "Clicking page 3 button...\n",
      "Scraping Page 3...\n",
      "Page 3 scraped. Total reviews so far: 15\n",
      "Clicking page 4 button...\n",
      "Scraping Page 4...\n",
      "Page 4 scraped. Total reviews so far: 20\n",
      "Clicking page 5 button...\n",
      "Scraping Page 5...\n",
      "Page 5 scraped. Total reviews so far: 25\n",
      "Clicking page 6 button...\n",
      "Scraping complete. 25 reviews saved to lazada_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import capsolver  # Import CapSolver\n",
    "\n",
    "# Set CapSolver API key\n",
    "capsolver.api_key = \"YOUR_CAPSOLVER_API_KEY\"  # Replace with your actual API key\n",
    "\n",
    "# Setup undetectable Chrome WebDriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.get(\"https://www.lazada.com.my/products/sweet-mint-eyeliner-silkworm-pen-glitter-nude-bright-waterproof-double-head-eyeliner-pen-eye-makeup-i3366129750-s18081596663.html\")\n",
    "time.sleep(random.uniform(5, 10))  # Random delay to mimic human behavior\n",
    "\n",
    "reviews_data = []\n",
    "max_pages = 5  # Number of pages to scrape\n",
    "\n",
    "# Function to solve CAPTCHA using CapSolver\n",
    "def solve_captcha():\n",
    "    print(\"CAPTCHA detected. Attempting to solve using CapSolver...\")\n",
    "    try:\n",
    "        solution = capsolver.solve({\n",
    "            \"type\": \"ReCaptchaV2TaskProxyless\",\n",
    "            \"websiteURL\": driver.current_url,\n",
    "            \"websiteKey\": \"SITE_KEY_HERE\"  # Replace with actual site key if known\n",
    "        })\n",
    "        print(f\"CAPTCHA solved: {solution}\")\n",
    "        time.sleep(10)  # Allow Lazada to verify the CAPTCHA solution\n",
    "        return solution\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to solve CAPTCHA: {e}\")\n",
    "        return None\n",
    "\n",
    "# Scrape multiple pages\n",
    "for page in range(1, max_pages + 1):\n",
    "    print(f\"Scraping Page {page}...\")\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(random.uniform(5, 10))  # Random delay\n",
    "\n",
    "    # Find all review elements\n",
    "    reviews = driver.find_elements(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[1]/div')\n",
    "\n",
    "    if not reviews:\n",
    "        print(\"No reviews found. Checking for CAPTCHA...\")\n",
    "        captcha_solution = solve_captcha()\n",
    "        if captcha_solution:\n",
    "            time.sleep(random.uniform(5, 10))  # Wait after solving CAPTCHA\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Could not solve CAPTCHA. Stopping the scraper.\")\n",
    "            break\n",
    "\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            reviewer = review.find_element(By.XPATH, \".//div[@class='middle']/span\").text.strip()\n",
    "        except:\n",
    "            reviewer = \"No Name\"\n",
    "\n",
    "        try:\n",
    "            date = review.find_element(By.XPATH, \".//span[@class='title right']\").text.strip()\n",
    "        except:\n",
    "            date = \"No Date\"\n",
    "\n",
    "        try:\n",
    "            content = review.find_element(By.XPATH, \".//div[@class='content']\").text.strip()\n",
    "        except:\n",
    "            content = \"No Review Content\"\n",
    "\n",
    "        reviews_data.append([reviewer, date, content])\n",
    "\n",
    "    print(f\"Page {page} scraped. Total reviews so far: {len(reviews_data)}\")\n",
    "\n",
    "    # Try navigating to the next page\n",
    "    try:\n",
    "        pagination_section = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[2]/div/div')\n",
    "        next_page_button = pagination_section.find_element(By.XPATH, f\".//button[contains(@class, 'next-pagination-item') and text()='{page + 1}']\")\n",
    "\n",
    "        if next_page_button:\n",
    "            print(f\"Clicking page {page + 1} button...\")\n",
    "\n",
    "            # Scroll to and click the next page button\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            time.sleep(random.uniform(3, 6))  # Random wait\n",
    "\n",
    "            driver.execute_script(\"window.scrollBy(0, -100);\")  # Adjust position to avoid overlap\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "\n",
    "            # Try clicking using JavaScript to bypass UI blocks\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "            # Wait until the reviews update to confirm page change\n",
    "            WebDriverWait(driver, 20).until(EC.staleness_of(reviews[0]))\n",
    "        else:\n",
    "            print(\"Next page button not found. Stopping scrape.\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating to next page: {e}\")\n",
    "        break\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Save reviews to CSV file\n",
    "df = pd.DataFrame(reviews_data, columns=[\"Reviewer Name\", \"Review Date\", \"Review Content\"])\n",
    "df.to_csv(\"lazada_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Scraping complete. {len(reviews_data)} reviews saved to lazada_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb738f1-81dd-4c7f-981a-95ef9bf19b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
